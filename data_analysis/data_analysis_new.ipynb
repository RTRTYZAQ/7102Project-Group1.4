{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "print(sys.executable)"
   ],
   "metadata": {
    "id": "vJgFU4FfijVo",
    "ExecuteTime": {
     "end_time": "2025-04-20T09:56:16.227946Z",
     "start_time": "2025-04-20T09:56:15.934803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\arin7102\\python.exe\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BpTvN0UjhL_S",
    "ExecuteTime": {
     "end_time": "2025-04-20T09:56:21.186483Z",
     "start_time": "2025-04-20T09:56:21.144868Z"
    }
   },
   "source": [
    "class Analysis:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def analyze_sales(self):\n",
    "        # 计算总销售额\n",
    "        sales_summation = self.data['Sales'].sum()\n",
    "        # 计算均值\n",
    "        sales_mean = round(self.data['Sales'].mean(), 3)\n",
    "        # 计算标准差\n",
    "        sales_std = round(self.data['Sales'].std(), 3)\n",
    "        # 计算最小值\n",
    "        sales_min = self.data['Sales'].min()\n",
    "        # 计算最大值\n",
    "        sales_max = self.data['Sales'].max()\n",
    "        # 计算25%、50%、75%的分位数（即分位数）\n",
    "        sales_percentiles = self.data['Sales'].quantile([0.25, 0.5, 0.75]).round(3)\n",
    "        \n",
    "        result = {\n",
    "            'sales_summation': sales_summation,\n",
    "            'sales_mean': sales_mean,\n",
    "            'sales_std': sales_std,\n",
    "            'sales_min': sales_min,\n",
    "            'sales_max': sales_max,\n",
    "            'sales_percentiles': {\n",
    "                '25%': sales_percentiles[0.25],\n",
    "                '50%': sales_percentiles[0.5],  # 中位数\n",
    "                '75%': sales_percentiles[0.75]\n",
    "            }\n",
    "        }\n",
    "        # 返回字典形式的所有统计结果\n",
    "        return {'sales_summary': result}\n",
    "\n",
    "    def analyze_quantity(self):\n",
    "        # 直接计算总数量，不分组\n",
    "        quantity_summation = self.data['Quantity'].sum()\n",
    "        # 计算均值\n",
    "        quantity_mean = round(self.data['Quantity'].mean(), 3)\n",
    "        # 计算标准差\n",
    "        quantity_std = round(self.data['Quantity'].std(), 3)\n",
    "        # 计算最小值\n",
    "        quantity_min = self.data['Quantity'].min()\n",
    "        # 计算最大值\n",
    "        quantity_max = self.data['Quantity'].max()\n",
    "        # 计算25%、50%、75%的分位数（即分位数）\n",
    "        quantity_percentiles = self.data['Quantity'].quantile([0.25, 0.5, 0.75]).round(3)\n",
    "        \n",
    "        \n",
    "        result = {\n",
    "            'quantity_summation': quantity_summation,\n",
    "            'quantity_mean': quantity_mean,\n",
    "            'quantity_std': quantity_std,\n",
    "            'quantity_min': quantity_min,\n",
    "            'quantity_max': quantity_max,\n",
    "            'quantity_percentiles': {\n",
    "                '25%': quantity_percentiles[0.25],\n",
    "                '50%': quantity_percentiles[0.5],  # 中位数\n",
    "                '75%': quantity_percentiles[0.75]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 返回字典形式的所有统计结果\n",
    "        return {'quantity_summary': result}\n",
    "\n",
    "    def analyze_price(self):\n",
    "        # 直接计算平均价格，不分组\n",
    "        price_avg = round(self.data['Price'].mean(), 3)\n",
    "        # 计算标准差\n",
    "        price_std = round(self.data['Price'].std(), 3)\n",
    "        # 计算最小值\n",
    "        price_min = self.data['Price'].min()\n",
    "        # 计算最大值\n",
    "        price_max = self.data['Price'].max()\n",
    "        # 计算25%、50%、75%的分位数（即分位数）\n",
    "        price_percentiles = self.data['Price'].quantile([0.25, 0.5, 0.75]).round(3)\n",
    "\n",
    "        result = {\n",
    "            'price_avg': price_avg,\n",
    "            'price_std': price_std,\n",
    "            'price_min': price_min,\n",
    "            'price_max': price_max,\n",
    "            'price_percentiles': {\n",
    "                '25%': price_percentiles[0.25],\n",
    "                '50%': price_percentiles[0.5],  # 中位数\n",
    "                '75%': price_percentiles[0.75]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return {'price_summary': result}\n",
    "\n",
    "    def analyze_year_distribution(self):\n",
    "        # 仅按 Year 分组\n",
    "        year_dist = self.data.groupby('Year').size()\n",
    "        year_dist_percentage = (year_dist / year_dist.sum() * 100).round(3)\n",
    "\n",
    "        # 转换为字典格式\n",
    "        result = {\n",
    "            str(year): {\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for year, count, percentage in zip(\n",
    "                year_dist.index,\n",
    "                year_dist,\n",
    "                year_dist_percentage\n",
    "            )\n",
    "        }\n",
    "        return {'year_distribution': result}\n",
    "\n",
    "    def analyze_month_distribution(self):\n",
    "        \"\"\"\n",
    "        分析月份分布\n",
    "        :return: 包含计数和百分比的字典\n",
    "        \"\"\"\n",
    "        month_dist = self.data['Month'].value_counts().sort_index()  # Ensure sorting by month\n",
    "        month_percentage = (month_dist / month_dist.sum() * 100).round(3)\n",
    "\n",
    "        month_dict = {\n",
    "            month: {\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for month, count, percentage in zip(\n",
    "                month_dist.index,\n",
    "                month_dist,\n",
    "                month_percentage\n",
    "            )\n",
    "        }\n",
    "\n",
    "        return {'month_distribution': month_dict}\n",
    "\n",
    "    def analyze_distributor_distribution(self):\n",
    "        # 计算分销商分布\n",
    "        distributor_dist = self.data['Distributor'].value_counts()\n",
    "        distributor_percentage = (distributor_dist / distributor_dist.sum() * 100).round(3)\n",
    "\n",
    "        distributor_dict = {\n",
    "            distributor: {\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for distributor, count, percentage in zip(\n",
    "                distributor_dist.index,\n",
    "                distributor_dist,\n",
    "                distributor_percentage\n",
    "            )\n",
    "        }\n",
    "        return {'distributor_distribution': distributor_dict}\n",
    "\n",
    "    def analyze_customer_distribution(self):\n",
    "        # 计算客户分布\n",
    "        # 不适用\n",
    "        customer_dist = self.data['Customer Name'].value_counts()\n",
    "        customer_percentage = (customer_dist / customer_dist.sum() * 100).round(3)\n",
    "\n",
    "        customer_dict = {\n",
    "            customer: {\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for customer, count, percentage in zip(\n",
    "                customer_dist.index,\n",
    "                customer_dist,\n",
    "                customer_percentage\n",
    "            )\n",
    "        }\n",
    "        return {'customer_distribution': customer_dict}\n",
    "\n",
    "    def analyze_city_distribution(self):\n",
    "        # 不适用\n",
    "        city_dist = self.data['City'].value_counts()\n",
    "        city_percentage = (city_dist / city_dist.sum() * 100).round(3)\n",
    "\n",
    "        city_dict = {\n",
    "            city: {\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for city, count, percentage in zip(\n",
    "                city_dist.index,\n",
    "                city_dist,\n",
    "                city_percentage\n",
    "            )\n",
    "        }\n",
    "        return {'city_distribution': city_dict}\n",
    "\n",
    "    # subchennel求和即为channel，多余\n",
    "    # def analyze_channel_distribution(self):\n",
    "    #     channel_dist = self.data['Channel'].value_counts()\n",
    "    #     channel_percentage = (channel_dist / channel_dist.sum() * 100).round(3)\n",
    "    # \n",
    "    #     channel_dict = {\n",
    "    #         channel: {\n",
    "    #             'count': int(count),\n",
    "    #             'percentage': float(percentage)\n",
    "    #         }\n",
    "    #         for channel, count, percentage in zip(\n",
    "    #             channel_dist.index,\n",
    "    #             channel_dist,\n",
    "    #             channel_percentage\n",
    "    #         )\n",
    "    #     }\n",
    "    #     return {'channel_distribution': channel_dict}\n",
    "\n",
    "    def analyze_channel_subchannel_distribution(self):\n",
    "        # 联合分布分析：Channel × Sub-channel\n",
    "        cross_dist = self.data.groupby(['Channel', 'Sub-channel']).size().unstack(fill_value=0)\n",
    "\n",
    "        # 计算各Channel内Sub-channel的百分比分布\n",
    "        channel_subchannel_percentage = cross_dist.div(cross_dist.sum(axis=1), axis=0) * 100\n",
    "\n",
    "        # 转换为嵌套字典格式\n",
    "        result = {}\n",
    "        for channel in cross_dist.index:\n",
    "            result[channel] = {}\n",
    "            for subchannel in cross_dist.columns:\n",
    "                if int(cross_dist.loc[channel, subchannel]) != 0:\n",
    "                  result[channel][subchannel] = {\n",
    "                      'count': int(cross_dist.loc[channel, subchannel]),\n",
    "                      'percentage': round(channel_subchannel_percentage.loc[channel, subchannel], 3)\n",
    "                  }\n",
    "\n",
    "        return {'channel_subchannel_distribution': result}\n",
    "\n",
    "    def analyze_product_distribution(self, top_n=20):\n",
    "        \"\"\"分析产品名称分布，默认显示前20个产品\"\"\"\n",
    "        #不适用\n",
    "        product_dist = self.data['Product Name'].value_counts()\n",
    "        product_percentage = (product_dist / product_dist.sum() * 100).round(3)\n",
    "\n",
    "        # 获取前top_n个产品\n",
    "        top_products = product_dist.head(top_n)\n",
    "        other_count = product_dist.sum() - top_products.sum()\n",
    "        other_percentage = (other_count / product_dist.sum() * 100).round(3)\n",
    "\n",
    "        product_dict = {\n",
    "            product: {\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for product, count, percentage in zip(\n",
    "                top_products.index,\n",
    "                top_products,\n",
    "                product_percentage.head(top_n)\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # 添加\"其他产品\"类别\n",
    "        if other_count > 0:\n",
    "            product_dict[\"Other Products\"] = {\n",
    "                'count': int(other_count),\n",
    "                'percentage': float(other_percentage)\n",
    "            }\n",
    "\n",
    "        return {'product_distribution': product_dict}\n",
    "\n",
    "    def analyze_sales_rep_distribution(self, top_n=15):\n",
    "        \"\"\"\n",
    "        分析销售代表分布\n",
    "        :param top_n: 显示前多少位销售代表，其余归类为\"Other Reps\"\n",
    "        :return: 包含计数和百分比的字典\n",
    "        \"\"\"\n",
    "        rep_dist = self.data['Name of Sales Rep'].value_counts()\n",
    "        rep_percentage = (rep_dist / rep_dist.sum() * 100).round(3)\n",
    "        \n",
    "        rep_team_mapping = (\n",
    "            self.data[['Name of Sales Rep', 'Sales Team']]\n",
    "            .drop_duplicates(subset='Name of Sales Rep', keep='first')\n",
    "            .set_index('Name of Sales Rep')['Sales Team']\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        # 获取前top_n位销售代表\n",
    "        top_reps = rep_dist.head(top_n)\n",
    "        other_count = rep_dist.sum() - top_reps.sum()\n",
    "        other_percentage = (other_count / rep_dist.sum() * 100).round(3)\n",
    "\n",
    "        rep_dict = {\n",
    "            rep: {\n",
    "                'Sales Team': rep_team_mapping.get(rep, None),\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage),\n",
    "                'performance_rank': rank + 1  # 添加绩效排名(按订单量)\n",
    "            }\n",
    "            for rank, (rep, count, percentage) in enumerate(zip(\n",
    "                top_reps.index,\n",
    "                top_reps,\n",
    "                rep_percentage.head(top_n)\n",
    "            ))\n",
    "        }\n",
    "\n",
    "        # 添加\"其他代表\"类别\n",
    "        if other_count > 0:\n",
    "            rep_dict[\"Other Reps\"] = {\n",
    "                'count': int(other_count),\n",
    "                'percentage': float(other_percentage),\n",
    "                'performance_rank': None\n",
    "            }\n",
    "\n",
    "        return {'sales_rep_distribution': rep_dict}\n",
    "\n",
    "    #  销售团队和经理分布完全一致，不需要再次分析\n",
    "    # def analyze_manager_distribution(self):\n",
    "    #     \"\"\"\n",
    "    #     分析经理分布\n",
    "    #     :return: 包含计数和百分比的字典\n",
    "    #     \"\"\"\n",
    "    #     manager_dist = self.data['Manager'].value_counts()\n",
    "    #     manager_percentage = (manager_dist / manager_dist.sum() * 100).round(2)\n",
    "    # \n",
    "    #     manager_dict = {\n",
    "    #         manager: {\n",
    "    #             'count': int(count),\n",
    "    #             'percentage': float(percentage)\n",
    "    #         }\n",
    "    #         for manager, count, percentage in zip(\n",
    "    #             manager_dist.index,\n",
    "    #             manager_dist,\n",
    "    #             manager_percentage\n",
    "    #         )\n",
    "    #     }\n",
    "    # \n",
    "    #     return {'manager_distribution': manager_dict}\n",
    "\n",
    "    \n",
    "    def analyze_sales_team_distribution(self):\n",
    "        \"\"\"\n",
    "        分析销售团队分布\n",
    "        :return: 包含计数和百分比的字典\n",
    "        \"\"\"\n",
    "        team_manager_mapping = {\n",
    "            \"Delta\": \"Britanny Bold\",\n",
    "            \"Alfa\": \"James Goodwill\",\n",
    "            \"Charlie\": \"Alisha Cordwell\",\n",
    "            \"Bravo\": \"Tracy Banks\"\n",
    "        }\n",
    "        \n",
    "        sales_team_dist = self.data['Sales Team'].value_counts()\n",
    "        sales_team_percentage = (sales_team_dist / sales_team_dist.sum() * 100).round(3)\n",
    "\n",
    "        sales_team_dict = {\n",
    "            team: {\n",
    "                'manager': team_manager_mapping.get(team, None),\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for team, count, percentage in zip(\n",
    "                sales_team_dist.index,\n",
    "                sales_team_dist,\n",
    "                sales_team_percentage\n",
    "            )\n",
    "        }\n",
    "\n",
    "        return {'sales_team_distribution': sales_team_dict}\n",
    "    \n",
    "    \n",
    "    def analyze_temporal_trends(self):\n",
    "        \"\"\"时间序列趋势分析\"\"\"\n",
    "        yearly_sales = self.data.groupby('Year')['Sales'].sum()\n",
    "        yearly_growth = yearly_sales.pct_change().dropna().mul(100).round(1)\n",
    "        \n",
    "        monthly_sales = self.data.groupby('Month')['Sales'].sum()\n",
    "        monthly_rank = monthly_sales.rank(ascending=False).astype(int)\n",
    "        \n",
    "        result = {\n",
    "            \"yearly_growth\": yearly_growth.to_dict(),\n",
    "            \"monthly_seasonality\": {\n",
    "                \"peak_months\": monthly_rank[monthly_rank <= 3].index.tolist(),\n",
    "                \"trough_months\": monthly_rank[monthly_rank >= 9].index.tolist()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return {'temporal_trends': result}\n",
    "\n",
    "\n",
    "    def analyze_geospatial_analysis(self):\n",
    "        \"\"\"地理空间分析\"\"\"\n",
    "        result = {\n",
    "            \"top_cities\": self._top_cities_analysis(),\n",
    "            \"geo_clusters\": self._detect_geo_clusters()\n",
    "        }\n",
    "        return {'geospatial_analysis': result}\n",
    "\n",
    "    def _top_cities_analysis(self, top_n=10):\n",
    "        \"\"\"城市销售排名分析\"\"\"\n",
    "        city_stats = self.data.groupby('City').agg(\n",
    "            total_sales=('Sales', 'sum'),\n",
    "            unique_customers=('Customer Name', 'nunique')\n",
    "        ).sort_values('total_sales', ascending=False)\n",
    "        return city_stats.head(top_n).to_dict(orient='index')\n",
    "\n",
    "    def _detect_geo_clusters(self):\n",
    "        \"\"\"地理聚类分析\"\"\"\n",
    "        coords = self.data[['Latitude', 'Longitude']].dropna()\n",
    "        if len(coords) == 0:\n",
    "            return []\n",
    "            \n",
    "        scaled = StandardScaler().fit_transform(coords)\n",
    "        db = DBSCAN(eps=0.5, min_samples=10).fit(scaled)\n",
    "        coords['cluster'] = db.labels_\n",
    "        \n",
    "        clusters = coords[coords['cluster'] != -1]\n",
    "        \n",
    "        cluster_stats = clusters.groupby('cluster').agg(\n",
    "            latitude_range=('Latitude', lambda x: f\"{x.min():.1f}-{x.max():.1f}\"),\n",
    "            longitude_range=('Longitude', lambda x: f\"{x.min():.1f}-{x.max():.1f}\"),\n",
    "            point_count=('Latitude', 'count')\n",
    "        ).sort_values('point_count', ascending=False)\n",
    "        \n",
    "        return cluster_stats.to_dict(orient='records')\n",
    "\n",
    "\n",
    "    def analyze_product_analysis(self):\n",
    "        \"\"\"产品维度分析\"\"\"\n",
    "        result = {\n",
    "            \"top_products\": self._top_products_analysis(),\n",
    "            \"price_elasticity\": self._price_elasticity_analysis()\n",
    "        }\n",
    "        return {'product_analysis': result}\n",
    "\n",
    "    def _top_products_analysis(self, top_n=10):\n",
    "        \"\"\"畅销产品分析\"\"\"\n",
    "        product_stats = self.data.groupby('Product Name').agg(\n",
    "            total_sales=('Sales', 'sum'),\n",
    "            units_sold=('Quantity', 'sum'),\n",
    "            avg_price=('Price', 'mean')\n",
    "        ).sort_values('total_sales', ascending=False)\n",
    "        return product_stats.head(top_n).to_dict(orient='index')\n",
    "\n",
    "    def _price_elasticity_analysis(self):\n",
    "        \"\"\"价格敏感性分析\"\"\"\n",
    "        X = self.data[['Quantity', 'Price']].dropna()\n",
    "        X_scaled = StandardScaler().fit_transform(X)\n",
    "        \n",
    "        kmeans = KMeans(n_clusters=2, random_state=0).fit(X_scaled)\n",
    "        clusters = pd.Series(kmeans.labels_, index=X.index)\n",
    "        \n",
    "        cluster_stats = X.groupby(clusters).agg(\n",
    "            avg_quantity=('Quantity', 'mean'),\n",
    "            avg_price=('Price', 'mean'),\n",
    "            count=('Quantity', 'count')\n",
    "        ).to_dict(orient='index')\n",
    "        \n",
    "        return {\n",
    "            \"cluster_definitions\": cluster_stats,\n",
    "            \"sensitivity_labels\": {\n",
    "                0: \"Price Sensitive\",\n",
    "                1: \"Value Focused\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    def analyze_all(self):\n",
    "        return {\n",
    "            **self.analyze_year_distribution(),\n",
    "            **self.analyze_month_distribution(),\n",
    "            **self.analyze_sales(),\n",
    "            **self.analyze_quantity(),\n",
    "            **self.analyze_price(),\n",
    "            **self.analyze_distributor_distribution(),\n",
    "            # **self.analyze_channel_distribution(),\n",
    "            **self.analyze_channel_subchannel_distribution(),\n",
    "            **self.analyze_sales_rep_distribution(),\n",
    "            # **self.analyze_manager_distribution(),\n",
    "            **self.analyze_sales_team_distribution(),\n",
    "            **self.analyze_temporal_trends(),\n",
    "            **self.analyze_geospatial_analysis(),\n",
    "            **self.analyze_product_analysis(),\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# 数据读取与预处理\n",
    "data = pd.read_csv('../data/Pharm Data_Data.csv')\n",
    "\n",
    "# 拼接Product Class和Country列\n",
    "data['Product Class-Country'] = data['Product Class'] + '-' + data['Country']\n",
    "data.drop(columns=['Product Class', 'Country'], inplace=True)\n",
    "\n",
    "# 拼接时间，转化为datetime\n",
    "month_mapping = {\n",
    "    'January': '01', 'Jan': '01',\n",
    "    'February': '02', 'Feb': '02', \n",
    "    'March': '03', 'Mar': '03',\n",
    "    'April': '04', 'Apr': '04',\n",
    "    'May': '05', \n",
    "    'June': '06', 'Jun': '06',\n",
    "    'July': '07', 'Jul': '07',\n",
    "    'August': '08', 'Aug': '08',\n",
    "    'September': '09', 'Sep': '09', 'Sept': '09',\n",
    "    'October': '10', 'Oct': '10',\n",
    "    'November': '11', 'Nov': '11',\n",
    "    'December': '12', 'Dec': '12'\n",
    "}\n",
    "data['Time'] = data['Year'].astype(str) + '-' + data['Month'].map(month_mapping)\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "data['YearMonth'] = data['Time'].dt.to_period('M')\n",
    "data.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "# 处理多余空格\n",
    "data['Distributor'] = data['Distributor'].str.strip()\n",
    "data['Customer Name'] = data['Customer Name'].str.strip()\n",
    "data.head()"
   ],
   "metadata": {
    "id": "IDu22vWciqjO",
    "ExecuteTime": {
     "end_time": "2025-04-20T09:56:28.798390Z",
     "start_time": "2025-04-20T09:56:27.805474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Distributor                         Customer Name     City  \\\n",
       "0  Gottlieb-Cruickshank                Zieme, Doyle and Kunze   Lublin   \n",
       "1  Gottlieb-Cruickshank                             Feest PLC  Świecie   \n",
       "2  Gottlieb-Cruickshank  Medhurst-Beer Pharmaceutical Limited   Rybnik   \n",
       "3  Gottlieb-Cruickshank                 Barton Ltd Pharma Plc  Czeladź   \n",
       "4  Gottlieb-Cruickshank                  Keeling LLC Pharmacy  Olsztyn   \n",
       "\n",
       "   Latitude  Longitude   Channel  Sub-channel            Product Name  \\\n",
       "0   51.2333    22.5667  Hospital      Private              Topipizole   \n",
       "1   53.4167    18.4333  Pharmacy       Retail            Choriotrisin   \n",
       "2   50.0833    18.5000  Pharmacy  Institution               Acantaine   \n",
       "3   50.3333    19.0833  Hospital      Private    Lioletine Refliruvax   \n",
       "4   53.7800    20.4942  Pharmacy       Retail  Oxymotroban Fexoformin   \n",
       "\n",
       "   Quantity  Price   Sales    Month  Year Name of Sales Rep        Manager  \\\n",
       "0       4.0    368  1472.0  January  2018      Mary Gerrard  Britanny Bold   \n",
       "1       7.0    591  4137.0  January  2018     Jessica Smith  Britanny Bold   \n",
       "2      30.0     66  1980.0  January  2018      Steve Pepple    Tracy Banks   \n",
       "3       6.0    435  2610.0  January  2018      Mary Gerrard  Britanny Bold   \n",
       "4      20.0    458  9160.0  January  2018           Anne Wu  Britanny Bold   \n",
       "\n",
       "  Sales Team    Product Class-Country YearMonth  \n",
       "0      Delta  Mood Stabilizers-Poland   2018-01  \n",
       "1      Delta       Antibiotics-Poland   2018-01  \n",
       "2      Bravo       Antibiotics-Poland   2018-01  \n",
       "3      Delta        Analgesics-Poland   2018-01  \n",
       "4      Delta        Analgesics-Poland   2018-01  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distributor</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Sub-channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name of Sales Rep</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Sales Team</th>\n",
       "      <th>Product Class-Country</th>\n",
       "      <th>YearMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Zieme, Doyle and Kunze</td>\n",
       "      <td>Lublin</td>\n",
       "      <td>51.2333</td>\n",
       "      <td>22.5667</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Private</td>\n",
       "      <td>Topipizole</td>\n",
       "      <td>4.0</td>\n",
       "      <td>368</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Mary Gerrard</td>\n",
       "      <td>Britanny Bold</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Mood Stabilizers-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Feest PLC</td>\n",
       "      <td>Świecie</td>\n",
       "      <td>53.4167</td>\n",
       "      <td>18.4333</td>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Choriotrisin</td>\n",
       "      <td>7.0</td>\n",
       "      <td>591</td>\n",
       "      <td>4137.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jessica Smith</td>\n",
       "      <td>Britanny Bold</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Antibiotics-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Medhurst-Beer Pharmaceutical Limited</td>\n",
       "      <td>Rybnik</td>\n",
       "      <td>50.0833</td>\n",
       "      <td>18.5000</td>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>Institution</td>\n",
       "      <td>Acantaine</td>\n",
       "      <td>30.0</td>\n",
       "      <td>66</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Steve Pepple</td>\n",
       "      <td>Tracy Banks</td>\n",
       "      <td>Bravo</td>\n",
       "      <td>Antibiotics-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Barton Ltd Pharma Plc</td>\n",
       "      <td>Czeladź</td>\n",
       "      <td>50.3333</td>\n",
       "      <td>19.0833</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Private</td>\n",
       "      <td>Lioletine Refliruvax</td>\n",
       "      <td>6.0</td>\n",
       "      <td>435</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Mary Gerrard</td>\n",
       "      <td>Britanny Bold</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Analgesics-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Keeling LLC Pharmacy</td>\n",
       "      <td>Olsztyn</td>\n",
       "      <td>53.7800</td>\n",
       "      <td>20.4942</td>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Oxymotroban Fexoformin</td>\n",
       "      <td>20.0</td>\n",
       "      <td>458</td>\n",
       "      <td>9160.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Anne Wu</td>\n",
       "      <td>Britanny Bold</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Analgesics-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T09:56:32.004231Z",
     "start_time": "2025-04-20T09:56:31.997088Z"
    }
   },
   "cell_type": "code",
   "source": "print(data.columns)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Distributor', 'Customer Name', 'City', 'Latitude', 'Longitude',\n",
      "       'Channel', 'Sub-channel', 'Product Name', 'Quantity', 'Price', 'Sales',\n",
      "       'Month', 'Year', 'Name of Sales Rep', 'Manager', 'Sales Team',\n",
      "       'Product Class-Country', 'YearMonth'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists('analysis_result/Pharm-data'):\n",
    "    os.makedirs('analysis_result/Pharm-data')\n",
    "\n",
    "for category in data['Product Class-Country'].unique():\n",
    "    print(f'Processing: {category}')\n",
    "    category_data = data[data['Product Class-Country'] == category]\n",
    "    analysis = Analysis(category_data)\n",
    "    analysis_result = analysis.analyze_all()\n",
    "    #print(analysis_result)\n",
    "    with open(f'analysis_result/Pharm-data/analysis_result_{category}.json', 'w') as f:\n",
    "        json.dump(analysis_result, f, indent=4)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_S_m9U_PitGn",
    "outputId": "720d52c0-61d0-4e6c-d65a-795ac53b48f1",
    "ExecuteTime": {
     "end_time": "2025-04-20T09:58:41.998352Z",
     "start_time": "2025-04-20T09:58:30.862208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Mood Stabilizers-Poland\n",
      "Processing: Antibiotics-Poland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\arin7102\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Analgesics-Poland\n",
      "Processing: Antiseptics-Poland\n",
      "Processing: Antipiretics-Poland\n",
      "Processing: Antimalarial-Poland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\arin7102\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Mood Stabilizers-Germany\n",
      "Processing: Antipiretics-Germany\n",
      "Processing: Antimalarial-Germany\n",
      "Processing: Analgesics-Germany\n",
      "Processing: Antiseptics-Germany\n",
      "Processing: Antibiotics-Germany\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ]
}
