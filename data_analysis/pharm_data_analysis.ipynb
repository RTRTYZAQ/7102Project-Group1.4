{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJgFU4FfijVo",
    "ExecuteTime": {
     "end_time": "2025-04-22T10:28:48.094749Z",
     "start_time": "2025-04-22T10:28:45.490162Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, silhouette_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "print(sys.executable)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\arin7102\\python.exe\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BpTvN0UjhL_S",
    "ExecuteTime": {
     "end_time": "2025-04-22T10:59:40.606925Z",
     "start_time": "2025-04-22T10:59:40.519818Z"
    }
   },
   "source": [
    "class Analysis:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def analyze_sales(self):\n",
    "        '''\n",
    "        销售额分析\n",
    "        '''\n",
    "        # 计算总销售额\n",
    "        sales_summation = self.data['Sales'].sum()\n",
    "        # 计算均值\n",
    "        sales_mean = round(self.data['Sales'].mean(), 3)\n",
    "        # 计算标准差\n",
    "        sales_std = round(self.data['Sales'].std(), 3)\n",
    "        # 计算最小值\n",
    "        sales_min = self.data['Sales'].min()\n",
    "        # 计算最大值\n",
    "        sales_max = self.data['Sales'].max()\n",
    "        # 计算25%、50%、75%的分位数（即分位数）\n",
    "        sales_percentiles = self.data['Sales'].quantile([0.25, 0.5, 0.75]).round(3)\n",
    "        \n",
    "        result = {\n",
    "            'sales_summation': sales_summation,\n",
    "            'sales_mean': sales_mean,\n",
    "            'sales_std': sales_std,\n",
    "            'sales_min': sales_min,\n",
    "            'sales_max': sales_max,\n",
    "            'sales_percentiles': {\n",
    "                '25%': sales_percentiles[0.25],\n",
    "                '50%': sales_percentiles[0.5],  # 中位数\n",
    "                '75%': sales_percentiles[0.75]\n",
    "            }\n",
    "        }\n",
    "        # 返回字典形式的所有统计结果\n",
    "        return {'sales_summary': result}\n",
    "\n",
    "    def analyze_quantity(self):\n",
    "        '''\n",
    "        数量分析\n",
    "        '''\n",
    "        # 直接计算总数量，不分组\n",
    "        quantity_summation = self.data['Quantity'].sum()\n",
    "        # 计算均值\n",
    "        quantity_mean = round(self.data['Quantity'].mean(), 3)\n",
    "        # 计算标准差\n",
    "        quantity_std = round(self.data['Quantity'].std(), 3)\n",
    "        # 计算最小值\n",
    "        quantity_min = self.data['Quantity'].min()\n",
    "        # 计算最大值\n",
    "        quantity_max = self.data['Quantity'].max()\n",
    "        # 计算25%、50%、75%的分位数（即分位数）\n",
    "        quantity_percentiles = self.data['Quantity'].quantile([0.25, 0.5, 0.75]).round(3)\n",
    "        \n",
    "        \n",
    "        result = {\n",
    "            'quantity_summation': quantity_summation,\n",
    "            'quantity_mean': quantity_mean,\n",
    "            'quantity_std': quantity_std,\n",
    "            'quantity_min': quantity_min,\n",
    "            'quantity_max': quantity_max,\n",
    "            'quantity_percentiles': {\n",
    "                '25%': quantity_percentiles[0.25],\n",
    "                '50%': quantity_percentiles[0.5],  # 中位数\n",
    "                '75%': quantity_percentiles[0.75]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 返回字典形式的所有统计结果\n",
    "        return {'quantity_summary': result}\n",
    "\n",
    "    def analyze_price(self):\n",
    "        '''\n",
    "        价格分析\n",
    "        '''\n",
    "        # 直接计算平均价格，不分组\n",
    "        price_avg = round(self.data['Price'].mean(), 3)\n",
    "        # 计算标准差\n",
    "        price_std = round(self.data['Price'].std(), 3)\n",
    "        # 计算最小值\n",
    "        price_min = self.data['Price'].min()\n",
    "        # 计算最大值\n",
    "        price_max = self.data['Price'].max()\n",
    "        # 计算25%、50%、75%的分位数（即分位数）\n",
    "        price_percentiles = self.data['Price'].quantile([0.25, 0.5, 0.75]).round(3)\n",
    "\n",
    "        result = {\n",
    "            'price_avg': price_avg,\n",
    "            'price_std': price_std,\n",
    "            'price_min': price_min,\n",
    "            'price_max': price_max,\n",
    "            'price_percentiles': {\n",
    "                '25%': price_percentiles[0.25],\n",
    "                '50%': price_percentiles[0.5],  # 中位数\n",
    "                '75%': price_percentiles[0.75]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return {'price_summary': result}\n",
    "\n",
    "\n",
    "    def analyze_year_distribution(self):\n",
    "        '''\n",
    "        年份分布分析\n",
    "        '''\n",
    "        # 仅按 Year 分组\n",
    "        year_dist = self.data.groupby('Year').size()\n",
    "        year_dist_percentage = (year_dist / year_dist.sum() * 100).round(3)\n",
    "\n",
    "        # 转换为字典格式\n",
    "        result = {\n",
    "            str(year): {\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for year, count, percentage in zip(\n",
    "                year_dist.index,\n",
    "                year_dist,\n",
    "                year_dist_percentage\n",
    "            )\n",
    "        }\n",
    "        return {'year_distribution': result}\n",
    "\n",
    "    \n",
    "    def analyze_month_distribution(self):\n",
    "        '''\n",
    "        月份分布分析\n",
    "        '''\n",
    "        month_dist = self.data['Month'].value_counts().sort_index()  # Ensure sorting by month\n",
    "        month_percentage = (month_dist / month_dist.sum() * 100).round(3)\n",
    "\n",
    "        month_dict = {\n",
    "            month: {\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage)\n",
    "            }\n",
    "            for month, count, percentage in zip(\n",
    "                month_dist.index,\n",
    "                month_dist,\n",
    "                month_percentage\n",
    "            )\n",
    "        }\n",
    "\n",
    "        return {'month_distribution': month_dict}\n",
    "\n",
    "\n",
    "    def analyze_distributor_performance(self, top_n=10):\n",
    "\n",
    "        if 'Distributor' not in self.data.columns or 'Sales' not in self.data.columns:\n",
    "            return {'distributor_performance': {'error': \"Required columns ('Distributor', 'Sales') not found.\"}}\n",
    "\n",
    "        distributor_sales = self.data.groupby('Distributor')['Sales'].sum().nlargest(top_n)\n",
    "\n",
    "        if distributor_sales.empty:\n",
    "            return {'distributor_performance': {}}\n",
    "\n",
    "        total_sales = self.data['Sales'].sum()\n",
    "        result = {}\n",
    "        if total_sales > 0:\n",
    "            sales_percentage = (distributor_sales / total_sales * 100).round(3)\n",
    "            result = {\n",
    "                distributor: {\n",
    "                    'total_sales': round(float(sales), 2),\n",
    "                    'percentage_of_total_sales': float(percentage)\n",
    "                }\n",
    "                for distributor, sales, percentage in zip(\n",
    "                    distributor_sales.index,\n",
    "                    distributor_sales,\n",
    "                    sales_percentage\n",
    "                )\n",
    "            }\n",
    "        else: # Handle case where total_sales is zero\n",
    "             result = {\n",
    "                distributor: {\n",
    "                    'total_sales': round(float(sales), 2),\n",
    "                    'percentage_of_total_sales': 0.0\n",
    "                }\n",
    "                for distributor, sales in distributor_sales.items()\n",
    "            }\n",
    "\n",
    "        return {f'top_{top_n}_distributor_performance': result}\n",
    "\n",
    "\n",
    "    def analyze_top_sales_reps(self, top_n=15):\n",
    "        \"\"\"\n",
    "        分析销售代表分布\n",
    "\n",
    "        :param top_n: 显示前多少位销售代表，其余归类为\"Other Reps\"\n",
    "\n",
    "        :return: 包含计数和百分比的字典\n",
    "        \"\"\"\n",
    "        rep_dist = self.data['Name of Sales Rep'].value_counts()\n",
    "        rep_percentage = (rep_dist / rep_dist.sum() * 100).round(3)\n",
    "        \n",
    "        rep_team_mapping = (\n",
    "            self.data[['Name of Sales Rep', 'Sales Team']]\n",
    "            .drop_duplicates(subset='Name of Sales Rep', keep='first')\n",
    "            .set_index('Name of Sales Rep')['Sales Team']\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        # 获取前top_n位销售代表\n",
    "        top_reps = rep_dist.head(top_n)\n",
    "        other_count = rep_dist.sum() - top_reps.sum()\n",
    "        other_percentage = (other_count / rep_dist.sum() * 100).round(3)\n",
    "\n",
    "        rep_dict = {\n",
    "            rep: {\n",
    "                'Sales Team': rep_team_mapping.get(rep, None),\n",
    "                'count': int(count),\n",
    "                'percentage': float(percentage),\n",
    "                'performance_rank': rank + 1  # 添加绩效排名(按订单量)\n",
    "            }\n",
    "            for rank, (rep, count, percentage) in enumerate(zip(\n",
    "                top_reps.index,\n",
    "                top_reps,\n",
    "                rep_percentage.head(top_n)\n",
    "            ))\n",
    "        }\n",
    "\n",
    "        # 添加\"其他代表\"类别\n",
    "        if other_count > 0:\n",
    "            rep_dict[\"Other Reps\"] = {\n",
    "                'count': int(other_count),\n",
    "                'percentage': float(other_percentage),\n",
    "                'performance_rank': None\n",
    "            }\n",
    "\n",
    "        return {'sales_rep_distribution': rep_dict}\n",
    "\n",
    "    \n",
    "    \n",
    "    def analyze_channels(self):\n",
    "        \"\"\"\n",
    "        分析渠道表现（包含全局占比）\n",
    "        \"\"\"\n",
    "        # 计算全局总量\n",
    "        global_sales = self.data['Sales'].sum()\n",
    "        global_orders = self.data['Customer Name'].count()\n",
    "        \n",
    "        # 计算渠道数据\n",
    "        channel_total = self.data.groupby('Channel').agg(\n",
    "            channel_sales=('Sales', 'sum'),\n",
    "            channel_orders=('Customer Name', 'count')\n",
    "        ).reset_index()\n",
    "        \n",
    "        # 计算子渠道数据\n",
    "        subchannel_detail = self.data.groupby(['Channel', 'Sub-channel']).agg(\n",
    "            sub_sales=('Sales', 'sum'),\n",
    "            sub_orders=('Customer Name', 'count')\n",
    "        ).reset_index()\n",
    "        \n",
    "        # 合并计算各级占比\n",
    "        merged = pd.merge(subchannel_detail, channel_total, on='Channel')\n",
    "        # 主渠道全局占比\n",
    "        merged['channel_sales_pct'] = (merged['channel_sales'] / global_sales * 100).round(3)\n",
    "        merged['channel_orders_pct'] = (merged['channel_orders'] / global_orders * 100).round(3)\n",
    "        # 子渠道局部占比\n",
    "        merged['sub_sales_pct'] = (merged['sub_sales'] / merged['channel_sales'] * 100).round(3)\n",
    "        merged['sub_orders_pct'] = (merged['sub_orders'] / merged['channel_orders'] * 100).round(3)\n",
    "        \n",
    "        # 构建嵌套结构\n",
    "        result = {}\n",
    "        for _, row in merged.iterrows():\n",
    "            channel = str(row['Channel'])\n",
    "            sub = str(row['Sub-channel'])\n",
    "            \n",
    "            if channel not in result:\n",
    "                result[channel] = {\n",
    "                    'global_sales_share': float(row['channel_sales_pct']),  # 主渠道全局销售占比\n",
    "                    'global_order_share': float(row['channel_orders_pct']),  # 主渠道全局订单占比\n",
    "                    'total_sales': float(round(row['channel_sales'], 2)),\n",
    "                    'total_orders': int(row['channel_orders']),\n",
    "                    'sub_channels': {}\n",
    "                }\n",
    "                \n",
    "            result[channel]['sub_channels'][sub] = {\n",
    "                'sub_sales': float(round(row['sub_sales'], 2)),\n",
    "                'sub_orders': int(row['sub_orders']),\n",
    "                'channel_sales_share': float(row['sub_sales_pct']),  # 子渠道在所属主渠道的销售占比\n",
    "                'channel_order_share': float(row['sub_orders_pct']),  # 子渠道在所属主渠道的订单占比\n",
    "                'global_sales_share': float((row['sub_sales'] / global_sales * 100).round(3)),  # 子渠道全局销售占比\n",
    "                'global_order_share': float((row['sub_orders'] / global_orders * 100).round(3))  # 子渠道全局订单占比\n",
    "            }\n",
    "        \n",
    "        return {'channel_performance': result}\n",
    "\n",
    "    \n",
    "    def analyze_sales_trend(self):\n",
    "        \"\"\"\n",
    "        分析销售额每月变化趋势\n",
    "\n",
    "        :return: timeline：时间线；sales：销售额；order_counts：订单数量\n",
    "        \"\"\"\n",
    "        trend = self.data.groupby('YearMonth')['Sales'].agg(['sum', 'count']).reset_index()\n",
    "        trend['month_str'] = trend['YearMonth'].dt.strftime('%Y-%m')\n",
    "        \n",
    "        return {\n",
    "            'sales_trend': {\n",
    "                'timeline': trend['month_str'].tolist(),\n",
    "                'sales': trend['sum'].round(2).tolist(),\n",
    "                'order_counts': trend['count'].tolist()\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    def analyze_pricing(self):\n",
    "        \"\"\"价格敏感度分析\"\"\"\n",
    "        price_bins = pd.cut(self.data['Price'], bins=5)\n",
    "        price_analysis = self.data.groupby(price_bins, observed=True).agg(\n",
    "            total_quantity=('Quantity', 'sum'),\n",
    "            total_sales=('Sales', 'sum'),\n",
    "            product_count=('Product Name', pd.Series.nunique)\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'price_sensitivity': {\n",
    "                str(interval): {\n",
    "                    'total_quantity': int(row['total_quantity']),\n",
    "                    'total_sales': float(round(row['total_sales'], 2)),\n",
    "                    'product_count': int(row['product_count'])\n",
    "                }\n",
    "                for interval, row in price_analysis.iterrows()\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    def analyze_teams(self):\n",
    "        \"\"\"\n",
    "        分析销售团队绩效\n",
    "        \"\"\"\n",
    "        # 计算全局总量\n",
    "        global_sales = self.data['Sales'].sum()\n",
    "        global_orders = self.data['Customer Name'].count()\n",
    "        \n",
    "        # 团队维度聚合\n",
    "        team_stats = self.data.groupby(['Sales Team', 'Manager']).agg(\n",
    "            total_sales=('Sales', 'sum'),\n",
    "            total_orders=('Customer Name', 'count'),\n",
    "            unique_customers=('Customer Name', pd.Series.nunique),\n",
    "            unique_reps=('Name of Sales Rep', pd.Series.nunique)\n",
    "        ).reset_index()\n",
    "        \n",
    "        # 计算各项占比\n",
    "        team_stats['sales_percentage'] = (team_stats['total_sales'] / global_sales * 100).round(3)\n",
    "        team_stats['order_percentage'] = (team_stats['total_orders'] / global_orders * 100).round(3)\n",
    "        \n",
    "        result = {}\n",
    "        for _, row in team_stats.iterrows():\n",
    "            team_name = str(row['Sales Team'])\n",
    "            result[team_name] = {\n",
    "                'manager': str(row['Manager']),\n",
    "                'total_sales': float(round(row['total_sales'], 2)),\n",
    "                'sales_percentage': float(row['sales_percentage']),  # 销售额全局占比\n",
    "                'total_orders': int(row['total_orders']),\n",
    "                'order_percentage': float(row['order_percentage']),  # 订单量全局占比\n",
    "                'avg_order_value': float(round(row['total_sales'] / row['total_orders'], 2)),\n",
    "                'unique_customers': int(row['unique_customers']),\n",
    "                'unique_reps': int(row['unique_reps'])  # 销售代表数量\n",
    "            }\n",
    "        \n",
    "        return {'team_performance': result}\n",
    "\n",
    "\n",
    "    def analyze_average_transaction_value(self):\n",
    "        \"\"\"\n",
    "        计算并分析平均交易额（单笔销售记录的平均 Sales 值）\n",
    "        也可以按不同维度（如渠道、产品类别）分析\n",
    "\n",
    "        :return: 包含总体平均交易额和按渠道的平均交易额的字典\n",
    "        \"\"\"\n",
    "        overall_avg_sales = self.data['Sales'].mean()\n",
    "        channel_avg_sales = self.data.groupby('Channel')['Sales'].mean().sort_values(ascending=False)\n",
    "\n",
    "        channel_avg_dict = {\n",
    "            channel: round(float(avg_val), 2)\n",
    "            for channel, avg_val in channel_avg_sales.items()\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'average_transaction_value': {\n",
    "                'overall': round(float(overall_avg_sales), 2),\n",
    "                'by_channel': channel_avg_dict\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "    def analyze_quantity_vs_price(self, top_n=5):\n",
    "        \"\"\"\n",
    "        分析销量最高和平均价格最高/最低的产品 (提供一些关于产品定位的洞察)\n",
    "\n",
    "        :param top_n: 返回排名前 N 的产品数量\n",
    "        :return: 包含高销量、高价、低价产品信息的字典\n",
    "        \"\"\"\n",
    "        # 按总销量排名\n",
    "        top_quantity_products = self.data.groupby('Product Name')['Quantity'].sum().nlargest(top_n)\n",
    "        # 计算每个产品的平均售价\n",
    "        avg_price_products = self.data.groupby('Product Name')['Price'].mean()\n",
    "\n",
    "        # 平均售价最高的产品\n",
    "        highest_avg_price = avg_price_products.nlargest(top_n)\n",
    "        # 平均售价最低的产品\n",
    "        lowest_avg_price = avg_price_products.nsmallest(top_n)\n",
    "\n",
    "        result = {\n",
    "            f'top_{top_n}_products_by_quantity': {\n",
    "                prod: int(qty) for prod, qty in top_quantity_products.items()\n",
    "            },\n",
    "            f'top_{top_n}_products_by_highest_avg_price': {\n",
    "                prod: round(float(price), 2) for prod, price in highest_avg_price.items()\n",
    "            },\n",
    "            f'top_{top_n}_products_by_lowest_avg_price': {\n",
    "                prod: round(float(price), 2) for prod, price in lowest_avg_price.items()\n",
    "            }\n",
    "        }\n",
    "        return {'quantity_vs_price_insights': result}\n",
    "\n",
    "\n",
    "    def analyze_top_customers(self, top_n=10):\n",
    "        \"\"\"\n",
    "        分析销售额最高的客户\n",
    "\n",
    "        :param top_n: 返回排名前 N 的客户数量\n",
    "        :return: 包含客户名和总销售额的字典\n",
    "        \"\"\"\n",
    "        top_customers = self.data.groupby('Customer Name')['Sales'].sum().nlargest(top_n)\n",
    "        result = {\n",
    "            customer: round(float(sales), 2)\n",
    "            for customer, sales in top_customers.items()\n",
    "        }\n",
    "        return {f'top_{top_n}_customers_by_sales': result}\n",
    "    \n",
    "\n",
    "    def analyze_customer_rfm(self):\n",
    "        \"\"\"\n",
    "        客户RFM分析（Recency, Frequency, Monetary）\n",
    "        \"\"\"\n",
    "        latest_month = self.data['YearMonth'].max()\n",
    "        rfm_data = self.data.groupby('Customer Name', observed=True).agg({\n",
    "            'YearMonth': lambda x: (latest_month - x.max()).n,  # Recency: 距离最近一次购买的月份间隔\n",
    "            'Quantity': 'count',           # Frequency: 购买次数\n",
    "            'Sales': 'sum'                 # Monetary: 总销售额\n",
    "        }).reset_index()\n",
    "        rfm_data.columns = ['Customer', 'Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "        quantiles = rfm_data[['Recency', 'Frequency', 'Monetary']].quantile(q=[0.2, 0.4, 0.6, 0.8]).to_dict()\n",
    "\n",
    "        def r_score(x):\n",
    "            if x <= quantiles['Recency'][0.2]: return 5\n",
    "            elif x <= quantiles['Recency'][0.4]: return 4\n",
    "            elif x <= quantiles['Recency'][0.6]: return 3\n",
    "            elif x <= quantiles['Recency'][0.8]: return 2\n",
    "            else: return 1\n",
    "\n",
    "        def fm_score(x, col):\n",
    "            if x <= quantiles[col][0.2]: return 1\n",
    "            elif x <= quantiles[col][0.4]: return 2\n",
    "            elif x <= quantiles[col][0.6]: return 3\n",
    "            elif x <= quantiles[col][0.8]: return 4\n",
    "            else: return 5\n",
    "\n",
    "        rfm_data['R_Score'] = rfm_data['Recency'].apply(r_score)\n",
    "        rfm_data['F_Score'] = rfm_data['Frequency'].apply(lambda x: fm_score(x, 'Frequency'))\n",
    "        rfm_data['M_Score'] = rfm_data['Monetary'].apply(lambda x: fm_score(x, 'Monetary'))\n",
    "        rfm_data['RFM_Score'] = rfm_data['R_Score'] + rfm_data['F_Score'] + rfm_data['M_Score']\n",
    "\n",
    "        rfm_data['Segment'] = pd.qcut(rfm_data['RFM_Score'], q=3, labels=['low', 'medium', 'high'])\n",
    "\n",
    "        segment_counts = rfm_data['Segment'].value_counts(normalize=True)\n",
    "\n",
    "        segment_analysis = rfm_data.groupby('Segment', observed=True).agg({\n",
    "            'Recency': 'mean',\n",
    "            'Frequency': 'mean',\n",
    "            'Monetary': 'mean',\n",
    "            'Customer': 'count'\n",
    "        }).rename(columns={'Customer': 'Customer Count'})\n",
    "\n",
    "        result = {\n",
    "            'value_ratio': segment_counts.to_dict(),\n",
    "            'value_analysis': {\n",
    "                str(segment): {\n",
    "                    'Recency': round(float(row['Recency']), 2),\n",
    "                    'Frequency': round(float(row['Frequency']), 2),\n",
    "                    'Monetary': round(float(row['Monetary']), 2),\n",
    "                    'Customer Count': int(row['Customer Count'])\n",
    "                } for segment, row in segment_analysis.iterrows()\n",
    "            }\n",
    "        }\n",
    "        return {'customer_rfm_analysis': result}\n",
    "    \n",
    "\n",
    "    def analyze_top_products(self, top_n=10):\n",
    "        \"\"\"\n",
    "        分析销售额最高的产品\n",
    "\n",
    "        :param top_n: 返回排名前 N 的产品数量\n",
    "        :return: 包含产品名和总销售额的字典\n",
    "        \"\"\"\n",
    "        top_products = self.data.groupby('Product Name', observed=True)['Sales'].sum().nlargest(top_n)\n",
    "        total_sales = self.data['Sales'].sum()\n",
    "        \n",
    "        result = {\n",
    "            product: {\n",
    "                'total_sales': round(float(sales), 2),\n",
    "                'percentage': float((sales / total_sales * 100).round(3))\n",
    "            }\n",
    "            for product, sales in top_products.items()\n",
    "        }\n",
    "        return {f'top_{top_n}_products_by_sales': result}\n",
    "    \n",
    "\n",
    "    def analyze_geo_preference(self, top_n=10):\n",
    "        '''\n",
    "        分析药品的地区偏好\n",
    "\n",
    "        :param top_n: 排名前n的城市\n",
    "        '''\n",
    "        country = self.data['Country'].unique()[0]\n",
    "        product_class = self.data['Product Class'].unique()[0]\n",
    "\n",
    "        result = self.data.groupby('City')['Sales'].sum().sort_values(ascending=False).head(top_n)\n",
    "        result = {\n",
    "            city: {\n",
    "                'total_sales': round(float(sales), 2),\n",
    "                'percentage': float((sales / self.data['Sales'].sum() * 100).round(3))\n",
    "            }\n",
    "            for city, sales in result.items()\n",
    "        }\n",
    "\n",
    "        return {f\"top_{top_n}_cities_in_{country}_by_sales_of_{product_class}\": result}\n",
    "    \n",
    "\n",
    "    def analyze_sales_regression(self):\n",
    "        \"\"\"\n",
    "        销售额回归分析\n",
    "        \"\"\"\n",
    "        features = self.data[[\n",
    "            'Quantity', \n",
    "            'Price', \n",
    "            'Channel',\n",
    "            'Sub-channel',\n",
    "            'Month', \n",
    "            'Sales Team'\n",
    "        ]]\n",
    "        feature_cols = features.columns.tolist()\n",
    "\n",
    "        target = self.data['Sales']\n",
    "        categorical_cols = ['Channel', 'Sub-channel', 'Month', 'Sales Team']\n",
    "        features_encoded = pd.get_dummies(features, columns=categorical_cols)\n",
    "\n",
    "        numeric_features = features_encoded[['Quantity', 'Price']]\n",
    "        correlation_matrix = numeric_features.corr()\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            features_encoded, \n",
    "            target, \n",
    "            test_size=0.2, \n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # 初始化模型\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "        coefficients = pd.DataFrame({\n",
    "            'Feature': features_encoded.columns,\n",
    "            'Coefficient': model.coef_\n",
    "        })\n",
    "\n",
    "        coefficients = coefficients.sort_values('Coefficient', ascending=False)\n",
    "\n",
    "        result = {\n",
    "            'r2_score': round(float(r2), 3),\n",
    "            'mean_squared_error': round(float(mse), 3),\n",
    "            'coefficients': {\n",
    "                feature_catagory: {\n",
    "                    feature: round(float(coef), 3)\n",
    "                    for feature, coef in zip(\n",
    "                        coefficients[coefficients['Feature'].str.contains(feature_catagory)]['Feature'].tolist(),\n",
    "                        coefficients[coefficients['Feature'].str.contains(feature_catagory)]['Coefficient'].tolist()\n",
    "                    )\n",
    "                } for feature_catagory in feature_cols\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        coefficients_abs = coefficients.copy()\n",
    "        coefficients_abs['Abs_Coefficient'] = coefficients_abs['Coefficient'].abs()\n",
    "        top_influential = coefficients_abs.sort_values('Abs_Coefficient', ascending=False).head(10)\n",
    "        \n",
    "        # 将这些最具影响力的特征添加到结果中\n",
    "        result['top_influential_features'] = {\n",
    "            feature: round(float(coef), 3)\n",
    "            for feature, coef in zip(\n",
    "                top_influential['Feature'].tolist(),\n",
    "                top_influential['Coefficient'].tolist()\n",
    "            )\n",
    "        }\n",
    "\n",
    "        return {'sales_regression_analysis': result}\n",
    "    \n",
    "\n",
    "    def analyze_clustering(self):\n",
    "        \"\"\"\n",
    "        销售数据聚类分析\n",
    "        \"\"\"\n",
    "        data_copy = self.data.copy()\n",
    "        features = data_copy[['Quantity', 'Price']]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "        kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(scaled_features)\n",
    "        score = silhouette_score(scaled_features, cluster_labels)\n",
    "\n",
    "        data_copy['Cluster'] = cluster_labels\n",
    "\n",
    "        cluster_centers_original = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "        cluster_centers_df = pd.DataFrame(cluster_centers_original, columns=features.columns)\n",
    "        cluster_centers_df['Cluster'] = range(2)\n",
    "        cluster_counts = data_copy['Cluster'].value_counts().sort_index()\n",
    "\n",
    "        result = {\n",
    "            'cluster_centers': {\n",
    "                f'Cluster {i}': {\n",
    "                    'Quantity': round(float(row['Quantity']), 2),\n",
    "                    'Price': round(float(row['Price']), 2)\n",
    "                } for i, row in cluster_centers_df.iterrows()\n",
    "            },\n",
    "            'cluster_counts': {\n",
    "                f'Cluster {i}': int(count) for i, count in cluster_counts.items()\n",
    "            },\n",
    "            'silhouette_score': round(float(score), 3)\n",
    "        }\n",
    "\n",
    "        return {'clustering_analysis': result}\n",
    "\n",
    "    def analyze_all(self):\n",
    "        return {\n",
    "            # 简单时间分布（行数过多，需要时再启用）\n",
    "            # **self.analyze_year_distribution(),\n",
    "            # **self.analyze_month_distribution(),\n",
    "\n",
    "            # 销售数据总览\n",
    "            **self.analyze_sales(),\n",
    "            **self.analyze_quantity(),\n",
    "            **self.analyze_price(),\n",
    "\n",
    "            # 经销商总体分析\n",
    "            **self.analyze_distributor_performance(),\n",
    "            # 销售团队/销售员分析\n",
    "            **self.analyze_teams(),\n",
    "            **self.analyze_top_sales_reps(),\n",
    "\n",
    "            # 每月销售情况趋势（行数过多，需要时再启用）\n",
    "            # **self.analyze_sales_trend(),\n",
    "\n",
    "            # 销售渠道分析\n",
    "            **self.analyze_channels(),\n",
    "            # 定价分析\n",
    "            **self.analyze_pricing(),\n",
    "\n",
    "            # 药品的地区偏好\n",
    "            **self.analyze_geo_preference(),\n",
    "\n",
    "            # 单笔平均销售额\n",
    "            **self.analyze_average_transaction_value(),\n",
    "\n",
    "            # 销售额最高的客户\n",
    "            **self.analyze_top_customers(),\n",
    "            # 客户RFM分析\n",
    "            **self.analyze_customer_rfm(),\n",
    "\n",
    "            # 分析销量最高和平均价格最高/最低的产品\n",
    "            **self.analyze_quantity_vs_price(),\n",
    "            # 销售额最高的产品\n",
    "            **self.analyze_top_products(),\n",
    "\n",
    "            # 销售额回归分析\n",
    "            **self.analyze_sales_regression(),\n",
    "\n",
    "            # 销售数据聚类分析\n",
    "            **self.analyze_clustering()\n",
    "            \n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IDu22vWciqjO",
    "ExecuteTime": {
     "end_time": "2025-04-22T10:29:04.760233Z",
     "start_time": "2025-04-22T10:29:03.773214Z"
    }
   },
   "source": [
    "data = pd.read_csv('../data/Pharm Data_Data.csv')\n",
    "\n",
    "data['Product Class-Country'] = data['Product Class'] + '-' + data['Country']\n",
    "\n",
    "month_mapping = {\n",
    "    'January': '01', 'Jan': '01',\n",
    "    'February': '02', 'Feb': '02', \n",
    "    'March': '03', 'Mar': '03',\n",
    "    'April': '04', 'Apr': '04',\n",
    "    'May': '05', \n",
    "    'June': '06', 'Jun': '06',\n",
    "    'July': '07', 'Jul': '07',\n",
    "    'August': '08', 'Aug': '08',\n",
    "    'September': '09', 'Sep': '09', 'Sept': '09',\n",
    "    'October': '10', 'Oct': '10',\n",
    "    'November': '11', 'Nov': '11',\n",
    "    'December': '12', 'Dec': '12'\n",
    "}\n",
    "data['Time'] = data['Year'].astype(str) + '-' + data['Month'].map(month_mapping)\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "data['YearMonth'] = data['Time'].dt.to_period('M')\n",
    "data.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "data['Distributor'] = data['Distributor'].str.strip()\n",
    "data['Customer Name'] = data['Customer Name'].str.strip()\n",
    "\n",
    "data = data[data['Quantity'] >= 0]\n",
    "\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Distributor                         Customer Name     City  \\\n",
       "0  Gottlieb-Cruickshank                Zieme, Doyle and Kunze   Lublin   \n",
       "1  Gottlieb-Cruickshank                             Feest PLC  Świecie   \n",
       "2  Gottlieb-Cruickshank  Medhurst-Beer Pharmaceutical Limited   Rybnik   \n",
       "3  Gottlieb-Cruickshank                 Barton Ltd Pharma Plc  Czeladź   \n",
       "4  Gottlieb-Cruickshank                  Keeling LLC Pharmacy  Olsztyn   \n",
       "\n",
       "  Country  Latitude  Longitude   Channel  Sub-channel            Product Name  \\\n",
       "0  Poland   51.2333    22.5667  Hospital      Private              Topipizole   \n",
       "1  Poland   53.4167    18.4333  Pharmacy       Retail            Choriotrisin   \n",
       "2  Poland   50.0833    18.5000  Pharmacy  Institution               Acantaine   \n",
       "3  Poland   50.3333    19.0833  Hospital      Private    Lioletine Refliruvax   \n",
       "4  Poland   53.7800    20.4942  Pharmacy       Retail  Oxymotroban Fexoformin   \n",
       "\n",
       "      Product Class  Quantity  Price   Sales    Month  Year Name of Sales Rep  \\\n",
       "0  Mood Stabilizers       4.0    368  1472.0  January  2018      Mary Gerrard   \n",
       "1       Antibiotics       7.0    591  4137.0  January  2018     Jessica Smith   \n",
       "2       Antibiotics      30.0     66  1980.0  January  2018      Steve Pepple   \n",
       "3        Analgesics       6.0    435  2610.0  January  2018      Mary Gerrard   \n",
       "4        Analgesics      20.0    458  9160.0  January  2018           Anne Wu   \n",
       "\n",
       "         Manager Sales Team    Product Class-Country YearMonth  \n",
       "0  Britanny Bold      Delta  Mood Stabilizers-Poland   2018-01  \n",
       "1  Britanny Bold      Delta       Antibiotics-Poland   2018-01  \n",
       "2    Tracy Banks      Bravo       Antibiotics-Poland   2018-01  \n",
       "3  Britanny Bold      Delta        Analgesics-Poland   2018-01  \n",
       "4  Britanny Bold      Delta        Analgesics-Poland   2018-01  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distributor</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Sub-channel</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Product Class</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name of Sales Rep</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Sales Team</th>\n",
       "      <th>Product Class-Country</th>\n",
       "      <th>YearMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Zieme, Doyle and Kunze</td>\n",
       "      <td>Lublin</td>\n",
       "      <td>Poland</td>\n",
       "      <td>51.2333</td>\n",
       "      <td>22.5667</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Private</td>\n",
       "      <td>Topipizole</td>\n",
       "      <td>Mood Stabilizers</td>\n",
       "      <td>4.0</td>\n",
       "      <td>368</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Mary Gerrard</td>\n",
       "      <td>Britanny Bold</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Mood Stabilizers-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Feest PLC</td>\n",
       "      <td>Świecie</td>\n",
       "      <td>Poland</td>\n",
       "      <td>53.4167</td>\n",
       "      <td>18.4333</td>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Choriotrisin</td>\n",
       "      <td>Antibiotics</td>\n",
       "      <td>7.0</td>\n",
       "      <td>591</td>\n",
       "      <td>4137.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Jessica Smith</td>\n",
       "      <td>Britanny Bold</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Antibiotics-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Medhurst-Beer Pharmaceutical Limited</td>\n",
       "      <td>Rybnik</td>\n",
       "      <td>Poland</td>\n",
       "      <td>50.0833</td>\n",
       "      <td>18.5000</td>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>Institution</td>\n",
       "      <td>Acantaine</td>\n",
       "      <td>Antibiotics</td>\n",
       "      <td>30.0</td>\n",
       "      <td>66</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Steve Pepple</td>\n",
       "      <td>Tracy Banks</td>\n",
       "      <td>Bravo</td>\n",
       "      <td>Antibiotics-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Barton Ltd Pharma Plc</td>\n",
       "      <td>Czeladź</td>\n",
       "      <td>Poland</td>\n",
       "      <td>50.3333</td>\n",
       "      <td>19.0833</td>\n",
       "      <td>Hospital</td>\n",
       "      <td>Private</td>\n",
       "      <td>Lioletine Refliruvax</td>\n",
       "      <td>Analgesics</td>\n",
       "      <td>6.0</td>\n",
       "      <td>435</td>\n",
       "      <td>2610.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Mary Gerrard</td>\n",
       "      <td>Britanny Bold</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Analgesics-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gottlieb-Cruickshank</td>\n",
       "      <td>Keeling LLC Pharmacy</td>\n",
       "      <td>Olsztyn</td>\n",
       "      <td>Poland</td>\n",
       "      <td>53.7800</td>\n",
       "      <td>20.4942</td>\n",
       "      <td>Pharmacy</td>\n",
       "      <td>Retail</td>\n",
       "      <td>Oxymotroban Fexoformin</td>\n",
       "      <td>Analgesics</td>\n",
       "      <td>20.0</td>\n",
       "      <td>458</td>\n",
       "      <td>9160.0</td>\n",
       "      <td>January</td>\n",
       "      <td>2018</td>\n",
       "      <td>Anne Wu</td>\n",
       "      <td>Britanny Bold</td>\n",
       "      <td>Delta</td>\n",
       "      <td>Analgesics-Poland</td>\n",
       "      <td>2018-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_S_m9U_PitGn",
    "outputId": "720d52c0-61d0-4e6c-d65a-795ac53b48f1",
    "ExecuteTime": {
     "end_time": "2025-04-22T11:01:15.963608Z",
     "start_time": "2025-04-22T10:59:43.847193Z"
    }
   },
   "source": [
    "if not os.path.exists('analysis_result/Pharm-data'):\n",
    "    os.makedirs('analysis_result/Pharm-data')\n",
    "\n",
    "for category in data['Product Class-Country'].unique():\n",
    "    print(f'Processing: {category}')\n",
    "    category_data = data[data['Product Class-Country'] == category]\n",
    "    analysis = Analysis(category_data)\n",
    "    analysis_result = analysis.analyze_all()\n",
    "    #print(analysis_result)\n",
    "    with open(f'analysis_result/Pharm-data/analysis_result_{category}.json', 'w') as f:\n",
    "        json.dump(analysis_result, f, indent=4)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Mood Stabilizers-Poland\n",
      "Processing: Antibiotics-Poland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\arin7102\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Analgesics-Poland\n",
      "Processing: Antiseptics-Poland\n",
      "Processing: Antipiretics-Poland\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda3\\envs\\arin7102\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=23.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Antimalarial-Poland\n",
      "Processing: Mood Stabilizers-Germany\n",
      "Processing: Antipiretics-Germany\n",
      "Processing: Antimalarial-Germany\n",
      "Processing: Analgesics-Germany\n",
      "Processing: Antiseptics-Germany\n",
      "Processing: Antibiotics-Germany\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "arin7102",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
